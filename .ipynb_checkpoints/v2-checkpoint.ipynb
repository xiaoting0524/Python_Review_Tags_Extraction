{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "from pandas.io.json import json_normalize #package for flattening json in pandas df\n",
    "\n",
    "#load json object\n",
    "    \n",
    "json_data = ''\n",
    "\n",
    "with open('yelp_dataset/review.json', 'r', encoding='utf-8') as in_file:\n",
    "    for i, line in enumerate(in_file):\n",
    "        if i == 0 and line: \n",
    "            json_data += '[' + line\n",
    "        elif line:\n",
    "            json_data += ',' + line\n",
    "        else:\n",
    "            pass\n",
    "    json_data += ']\\n'\n",
    "\n",
    "data = json.loads(json_data)\n",
    "review_df = json_normalize(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>1</td>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>6</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>0</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>3</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b1b1eb3uo-w561D0ZfCEiQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-30 23:07:38</td>\n",
       "      <td>0</td>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>7</td>\n",
       "      <td>ssoyf2_x0EQMed6fgHeMyQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                 date  funny  \\\n",
       "0  ujmEBvifdJM6h6RLv4wQIg     0  2013-05-07 04:34:36      1   \n",
       "1  NZnhc2sEQy3RmzKTZnqtwQ     0  2017-01-14 21:30:33      0   \n",
       "2  WTqjgwHlXbSFevF32_DJVw     0  2016-11-09 20:09:03      0   \n",
       "3  ikCg8xy5JIg_NGPx-MSIDA     0  2018-01-09 20:56:38      0   \n",
       "4  b1b1eb3uo-w561D0ZfCEiQ     0  2018-01-30 23:07:38      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q    1.0   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q    5.0   \n",
       "2  2TzJjDVDEuAW6MR5Vuc1ug    5.0   \n",
       "3  yi0R0Ugj_xUx_Nek0-_Qig    5.0   \n",
       "4  11a8sVPMUFtaC7_ABRkmtw    1.0   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  Total bill for this horrible service? Over $8G...       6   \n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...       0   \n",
       "2  I have to say that this office really has it t...       3   \n",
       "3  Went in for a lunch. Steak sandwich was delici...       0   \n",
       "4  Today was my second out of three sessions I ha...       7   \n",
       "\n",
       "                  user_id  \n",
       "0  hG7b0MtEbXx5QzbzE6C_VA  \n",
       "1  yXQM5uF2jS6es16SJzNHfg  \n",
       "2  n6-Gk65cPZL6Uz8qRm3NYw  \n",
       "3  dacAIZ6fTM6mqwW5uxkskg  \n",
       "4  ssoyf2_x0EQMed6fgHeMyQ  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "from pandas.io.json import json_normalize #package for flattening json in pandas df\n",
    "\n",
    "#load json object\n",
    "    \n",
    "json_data = ''\n",
    "\n",
    "with open('yelp_dataset/business.json', 'r', encoding='utf-8') as in_file:\n",
    "    for i, line in enumerate(in_file):\n",
    "        if i == 0 and line: \n",
    "            json_data += '[' + line\n",
    "        elif line:\n",
    "            json_data += ',' + line\n",
    "        else:\n",
    "            pass\n",
    "    json_data += ']\\n'\n",
    "\n",
    "data = json.loads(json_data)\n",
    "df = json_normalize(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Specialty Food, Restaurants, Dim Sum, Imported...</td>\n",
       "      <td>QXAEGFB4oINsVuTFxEYKFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sushi Bars, Restaurants, Japanese</td>\n",
       "      <td>gnKjwL_1w79qoiV3IC_xQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch, Mexican, Taco...</td>\n",
       "      <td>1Dfx3zM-rW4n-31KeC8sJg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Italian, Restaurants, Pizza, Chicken Wings</td>\n",
       "      <td>fweCYi8FmbJXHCqLnwuk8w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>PZ-LZzSlhSe9utkQYU8pFg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           categories             business_id\n",
       "1   Specialty Food, Restaurants, Dim Sum, Imported...  QXAEGFB4oINsVuTFxEYKFQ\n",
       "2                   Sushi Bars, Restaurants, Japanese  gnKjwL_1w79qoiV3IC_xQQ\n",
       "11  Restaurants, Breakfast & Brunch, Mexican, Taco...  1Dfx3zM-rW4n-31KeC8sJg\n",
       "13         Italian, Restaurants, Pizza, Chicken Wings  fweCYi8FmbJXHCqLnwuk8w\n",
       "17                               Restaurants, Italian  PZ-LZzSlhSe9utkQYU8pFg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df.categories.apply(lambda categories: str(categories))\n",
    "restaurant_df = df[temp.apply(lambda categories: 'Restaurants' in categories)][['categories',\"business_id\"]]\n",
    "restaurant_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_review = pd.merge(review_df,restaurant_df,on = 'business_id', how = 'left', sort = False)\n",
    "res_review=res_review.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6685900, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_review.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_r=res_review[res_review.categories!=0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4201684, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_r.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ikCg8xy5JIg_NGPx-MSIDA</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-09 20:56:38</td>\n",
       "      <td>0</td>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>0</td>\n",
       "      <td>dacAIZ6fTM6mqwW5uxkskg</td>\n",
       "      <td>Bars, Pubs, Nightlife, Tapas Bars, Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eU_713ec6fTGNO4BegRaww</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-20 13:25:59</td>\n",
       "      <td>0</td>\n",
       "      <td>fdiNeiN_hoCxCMy2wTRW9g</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I'll be the first to admit that I was not exci...</td>\n",
       "      <td>0</td>\n",
       "      <td>w31MKYsNFMrjhWxxAb5wIw</td>\n",
       "      <td>Restaurants, Italian, Pizza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-07 01:21:02</td>\n",
       "      <td>4</td>\n",
       "      <td>G7XHMxG0bx9oBJNECG4IFg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>5</td>\n",
       "      <td>jlu4CztcSxrKx56ba1a5AQ</td>\n",
       "      <td>Food, Chinese, Restaurants, Desserts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zvO-PJCpNk4fgAVUnExYAA</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-10-05 19:12:35</td>\n",
       "      <td>1</td>\n",
       "      <td>8e9HxxLjjqc9ez5ezzN7iQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This place has gone down hill.  Clearly they h...</td>\n",
       "      <td>3</td>\n",
       "      <td>d6xvYpyzcfbF_AZ8vMB7QA</td>\n",
       "      <td>Sports Bars, Bars, Restaurants, American (New)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8mIrX_LrOnAqWsB5JrOojQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-30 02:11:15</td>\n",
       "      <td>0</td>\n",
       "      <td>kbtscdyz6lvrtGjD1quQTg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Like walking back in time, every Saturday morn...</td>\n",
       "      <td>0</td>\n",
       "      <td>FIk4lQQu1eTe2EpzQ4xhBA</td>\n",
       "      <td>Performing Arts, Amusement Parks, Museums, Arc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id  cool                 date  funny  \\\n",
       "3   ikCg8xy5JIg_NGPx-MSIDA     0  2018-01-09 20:56:38      0   \n",
       "5   eU_713ec6fTGNO4BegRaww     0  2013-01-20 13:25:59      0   \n",
       "6   3fw2X5bZYeW9xCz_zGhOHg     5  2016-05-07 01:21:02      4   \n",
       "7   zvO-PJCpNk4fgAVUnExYAA     1  2010-10-05 19:12:35      1   \n",
       "10  8mIrX_LrOnAqWsB5JrOojQ     0  2011-11-30 02:11:15      0   \n",
       "\n",
       "                 review_id  stars  \\\n",
       "3   yi0R0Ugj_xUx_Nek0-_Qig    5.0   \n",
       "5   fdiNeiN_hoCxCMy2wTRW9g    4.0   \n",
       "6   G7XHMxG0bx9oBJNECG4IFg    3.0   \n",
       "7   8e9HxxLjjqc9ez5ezzN7iQ    1.0   \n",
       "10  kbtscdyz6lvrtGjD1quQTg    4.0   \n",
       "\n",
       "                                                 text  useful  \\\n",
       "3   Went in for a lunch. Steak sandwich was delici...       0   \n",
       "5   I'll be the first to admit that I was not exci...       0   \n",
       "6   Tracy dessert had a big name in Hong Kong and ...       5   \n",
       "7   This place has gone down hill.  Clearly they h...       3   \n",
       "10  Like walking back in time, every Saturday morn...       0   \n",
       "\n",
       "                   user_id                                         categories  \n",
       "3   dacAIZ6fTM6mqwW5uxkskg     Bars, Pubs, Nightlife, Tapas Bars, Restaurants  \n",
       "5   w31MKYsNFMrjhWxxAb5wIw                        Restaurants, Italian, Pizza  \n",
       "6   jlu4CztcSxrKx56ba1a5AQ               Food, Chinese, Restaurants, Desserts  \n",
       "7   d6xvYpyzcfbF_AZ8vMB7QA  Sports Bars, Bars, Restaurants, American (New)...  \n",
       "10  FIk4lQQu1eTe2EpzQ4xhBA  Performing Arts, Amusement Parks, Museums, Arc...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_r.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "char_splitter = re.compile(\"[.,;!:()-]?\")\n",
    "def generate_candidate_phrases(text, stopwords):\n",
    "    coarse_candidates = char_splitter.split(text.lower())\n",
    "    candidate_phrases = []\n",
    "    word=\"\"\n",
    "    n=0\n",
    "\n",
    "    for coarse_phrase in coarse_candidates:\n",
    "        words=re.split(\"\\\\s+\", coarse_phrase.strip())\n",
    "        previous_stop = False\n",
    "        start=True\n",
    "        for w in words:\n",
    "\n",
    "            w=w.translate(str.maketrans('', '', string.punctuation))\n",
    "            if w in stopwords and not previous_stop:\n",
    "\n",
    "                # phrase boundary encountered, so put a hard indicator\n",
    "                if n>1:          \n",
    "                    candidate_phrases.append(word)\n",
    "                previous_stop = True\n",
    "                word=\"\"\n",
    "                n=0\n",
    "            elif w in stopwords and previous_stop:\n",
    "\n",
    "                word=\"\"\n",
    "                n=0\n",
    "            elif w not in stopwords and len(w) > 3:\n",
    "                # keep adding words to list until a phrase boundary is detected\n",
    "                if start==True:\n",
    "                    n=1\n",
    "                    start=False\n",
    "                elif previous_stop==False:\n",
    "                    w=\"_\"+w\n",
    "                    n=n+1   \n",
    "                else:\n",
    "                    n=1\n",
    "                word+=w\n",
    "                previous_stop = False\n",
    "\n",
    "\n",
    "\n",
    "    if n>1:\n",
    "        candidate_phrases.append(word)\n",
    "\n",
    "    return candidate_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "sp = spacy.load('en') \n",
    "stop=list(sp.Defaults.stop_words) \n",
    "stop.append(\"said\")\n",
    "stop.append(\"came\")\n",
    "stop.append(\"tell\")\n",
    "stop.append(\"told\")\n",
    "stop.append(\"when\")\n",
    "stop.append(\"maybe\")\n",
    "stop.append(\"sure\")\n",
    "stop.append(\"like\")\n",
    "stop.append(\"it's\")\n",
    "stop.append(\"i'm\")\n",
    "stop.append(\"ask\")\n",
    "stop.append(\"asked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test=restaurant_r[\"text\"]\n",
    "p=[]\n",
    "for s in test:\n",
    "    p.append(generate_candidate_phrases(s,stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(426494954, 687270340)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "model = gensim.models.Word2Vec(\n",
    "        p,\n",
    "        size=200,\n",
    "        window=10,\n",
    "        min_count=10,\n",
    "        alpha=0.02,\n",
    "        workers=10)\n",
    "model.train(p, total_examples=len(p), epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=['super_friendly']\n",
    "model.wv.most_similar(w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('absolutely_recommend', 0.5035410523414612),\n",
       " ('highly_recommend_coming', 0.46933454275131226),\n",
       " ('highly_recommend_trying', 0.44521066546440125),\n",
       " ('delicioushighly_recommend', 0.4414668381214142),\n",
       " ('definitely_recommended', 0.42504408955574036),\n",
       " ('highlyhighly_recommend', 0.4145546853542328),\n",
       " ('highly_recommend_ordering', 0.41400277614593506),\n",
       " ('highly_recommend_dining', 0.3979026675224304),\n",
       " ('attentivehighly_recommend', 0.3969406485557556),\n",
       " ('certainly_recommend', 0.3948928713798523)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=['highly_recommend']\n",
    "model.wv.most_similar(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('feel_welcome', 0.4503967761993408),\n",
       " ('felt_comfortable', 0.40708303451538086),\n",
       " ('wasnt_stuffy', 0.4046385884284973),\n",
       " ('felt_welcome', 0.39923352003097534),\n",
       " ('feel_important', 0.38923385739326477),\n",
       " ('feel_right', 0.3871958255767822),\n",
       " ('genuine_service', 0.3838474154472351),\n",
       " ('pays_attention', 0.38256561756134033),\n",
       " ('dont_feel_intimidated', 0.37976330518722534),\n",
       " ('true_pleasure', 0.3779766857624054)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=['feel_comfortable']\n",
    "model.wv.most_similar(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('totally_uncalled', 0.7248241901397705),\n",
       " ('absolutely_rude', 0.7183749079704285),\n",
       " ('worse_customer_service', 0.7062989473342896),\n",
       " ('rude_employees', 0.7037721872329712),\n",
       " ('rude_behavior', 0.7006328701972961),\n",
       " ('rude_people', 0.6993989944458008),\n",
       " ('horribly_rude', 0.699008584022522),\n",
       " ('zero_customer_service_skills', 0.6949117183685303),\n",
       " ('unprofessional_staff', 0.6940279006958008),\n",
       " ('rudest_person', 0.6913320422172546)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=['rude_staff']\n",
    "model.wv.most_similar(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('best_italian_restaurants', 0.8069932460784912),\n",
       " ('best_italian_restaurant', 0.7794725894927979),\n",
       " ('best_italian_food', 0.7692257761955261),\n",
       " ('real_italian_food', 0.7584949135780334),\n",
       " ('great_italian_food', 0.7569869756698608),\n",
       " ('good_italian', 0.749237060546875),\n",
       " ('italian_meal', 0.747499406337738),\n",
       " ('authentic_italian_food', 0.7452435493469238),\n",
       " ('best_italian_places', 0.7436243891716003),\n",
       " ('amazing_italian_food', 0.7399834394454956)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=['best_italian']\n",
    "model.wv.most_similar(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tasted_pretty_good', 0.5841901302337646),\n",
       " ('pretty_delicious', 0.583003580570221),\n",
       " ('pretty_salty', 0.5723506212234497),\n",
       " ('pretty_yummy', 0.5682516098022461),\n",
       " ('pretty_tender', 0.5565012097358704),\n",
       " ('actually_pretty_good', 0.5532486438751221),\n",
       " ('pretty_good_experience', 0.547193169593811),\n",
       " ('pretty_decent', 0.5464555025100708),\n",
       " ('pretty_flavorful', 0.532289981842041),\n",
       " ('pretty_juicy', 0.5174604058265686)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=['pretty_good']\n",
    "model.wv.most_similar(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('awesome_place', 0.4812101125717163),\n",
       " ('perfect_place', 0.47813719511032104),\n",
       " ('goodgreat_place', 0.47130221128463745),\n",
       " ('placegreat_place', 0.4677448868751526),\n",
       " ('wonderful_place', 0.46472039818763733),\n",
       " ('excellent_spot', 0.4515402317047119),\n",
       " ('perfectgreat_place', 0.44868409633636475),\n",
       " ('yummygreat_place', 0.4450187087059021),\n",
       " ('excellent_place', 0.4443668723106384),\n",
       " ('perfect_spot', 0.4438163936138153)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1=['great_place']\n",
    "model.wv.most_similar(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "#cnt = Counter(label)\n",
    "#keys = list(k for k,_ in cnt.most_common())\n",
    "core=db.core_sample_indices_\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "group=[[]*n_clusters_ for _ in range(n_clusters_)]\n",
    "for i in core:\n",
    "    j=int(labels[i])\n",
    "    group[j].append(candidates[i])\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crab_tortellini',\n",
       " 'chicken_parm',\n",
       " 'highly_recommend',\n",
       " 'date_night',\n",
       " 'make_sure',\n",
       " 'excellent_dish',\n",
       " 'cooked_perfectly',\n",
       " 'garlic_bread']"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=[]\n",
    "for i in range(len(group)):\n",
    "    re=group[i]\n",
    "    if len(set(re))==1:\n",
    "        result.append(re[0])\n",
    "    else:\n",
    "        cnt = Counter(re)\n",
    "        a=cnt.most_common(1)\n",
    "        result.append(a[0][0])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "def get_predict(businessid):\n",
    "    test=res_review[\"text\"][res_review.business_id==businessid]\n",
    "    l=len(test)\n",
    "    if l<60:\n",
    "        minspl=3\n",
    "        eps=0.25\n",
    "    elif l<180:\n",
    "        minspl=5\n",
    "        eps=0.25\n",
    "    elif l<500:\n",
    "        minspl=8\n",
    "        eps=0.25\n",
    "    elif l<1000:\n",
    "        minspl=10\n",
    "        eps=0.25\n",
    "    elif l<2000:\n",
    "        minspl=12\n",
    "        eps=0.25\n",
    "    else:\n",
    "        minspl=15\n",
    "        eps=0.25\n",
    "    return prediction(test,eps,minspl)\n",
    "\n",
    "def prediction(test,eps=0.3,minspl=5):\n",
    "    ##get data \n",
    "    p1=[]\n",
    "    for s in test:\n",
    "        p1.append(generate_candidate_phrases(s,stop))\n",
    "    words=sum(p1,[])\n",
    "    ##remove uncommon words\n",
    "    candidates=[]\n",
    "    for a in words:\n",
    "        if a in model.wv:\n",
    "            candidates.append(a)\n",
    "    ##calculate similarity\n",
    "    sim=[[0]*len(candidates) for _ in range(len(candidates))]\n",
    "    for i in range(len(candidates)):\n",
    "        for j in range(i,len(candidates)):\n",
    "            d=model.wv.similarity(candidates[i],candidates[j])\n",
    "            sim[i][j]=d\n",
    "            sim[j][i]=d\n",
    "    sim=np.array(sim)\n",
    "    dis = sim.copy()\n",
    "    dis = 1. - dis\n",
    "    ##DBSCAN\n",
    "   \n",
    "    db = DBSCAN(metric=\"precomputed\",algorithm=\"brute\",eps=eps, min_samples=minspl).fit(dis)\n",
    "    labels = db.labels_\n",
    "    core=db.core_sample_indices_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    group=[[]*n_clusters_ for _ in range(n_clusters_)]\n",
    "    for i in core:\n",
    "        j=int(labels[i])\n",
    "        group[j].append(candidates[i])\n",
    "    result=[]\n",
    "    for i in range(len(group)):\n",
    "        re=group[i]\n",
    "        if len(set(re))==1:\n",
    "            result.append(re[0])\n",
    "        else:\n",
    "            cnt = Counter(re)\n",
    "            a=cnt.most_common(1)\n",
    "            result.append(a[0][0])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crab_tortellini', 'highly_recommend', 'best_italian_food', 'large_party', 'garlic_bread', 'chicken_cacciatore']\n"
     ]
    }
   ],
   "source": [
    "print(get_predict(\"eU_713ec6fTGNO4BegRaww\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tracy_dessert', 'hong_kong', 'markham_place', 'long_time', 'fresh_fruit', 'steamed_rice_roll', 'pretty_good', 'great_place', 'mango_pudding', 'fried_milk']\n"
     ]
    }
   ],
   "source": [
    "id='3fw2X5bZYeW9xCz_zGhOHg'\n",
    "print(get_predict(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pinball_machines', 'highly_recommend', 'good_time', 'great_selection', 'great_place', 'newer_ones', 'great_time', 'memory_lane', 'favorite_places', 'pretty_cool', 'play_games', 'youre_looking', 'cool_place', 'long_time', 'couple_hours', 'perfect_place', 'dont_think', 'awesome_place', 'dont_know', 'slot_machines', 'spend_hours', 'stop_yelling']\n"
     ]
    }
   ],
   "source": [
    "id='8mIrX_LrOnAqWsB5JrOojQ'\n",
    "print(get_predict(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dirtiest_places', 'health_inspections', 'rude_staff', 'kensington_location']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "id='ikCg8xy5JIg_NGPx-MSIDA'\n",
    "print(get_predict(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sports_grill', 'pool_tables', 'happy_hour']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: split() requires a non-empty pattern match.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "id='zvO-PJCpNk4fgAVUnExYAA'\n",
    "print(get_predict(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
